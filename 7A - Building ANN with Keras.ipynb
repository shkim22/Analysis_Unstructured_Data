{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882a05b9-cf47-4bcf-8d47-08c1876bdc3e",
   "metadata": {},
   "source": [
    "## Introduction to Keras ##\n",
    "### Building a Model\n",
    "Keras is a high-level API for building ANNs with lower-level machine learning languages, such as tensorflow. Historically, keras provided access to a variety of machine learning frameworks, but now it's used almost exclusively with tensorflow, one of the \"big 2\" machine learning frameworks (along with `pytorch`). \n",
    "\n",
    "Before we move in to setting up an ANN meant for some NLP task, like classification, let's learn how to build a simple ANN that we can use to learn some complex pattern we define in some synthetic data.\n",
    "\n",
    "For our purposes, we're going to use the `Sequential` API within Keras, which means we build our models step-by-step (i.e., each layer is added sequentially). We will also stick with `Dense`, or fully connected layers. \n",
    "\n",
    "Let's import the necessary components to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c592775-1f15-42d5-8934-d21eae9708a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027734fa-8284-48c2-a03f-56fbbb1f9719",
   "metadata": {},
   "source": [
    "If you recall, in the slides we had this neural network:\n",
    "\n",
    "![image](7A-image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0e8f2-2acd-442f-b580-2cccea2d94e7",
   "metadata": {},
   "source": [
    "Let's describe this in words, and then we'll convert that to an ANN defined with Keras:\n",
    "1. The input layer has 3 nodes\n",
    "2. The first hidden layer has 2 nodes\n",
    "3. The second hidden layer has 4 nodes\n",
    "4. The third hidden layer has 3 nodes\n",
    "5. The output layer has one node.\n",
    "\n",
    "Here's how we'd set this up with Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f62787-e5f1-45fc-9905-c30af8eaf977",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # establish the sequential ANN\n",
    "# First hidden layer:\n",
    "model.add(Dense(2,input_shape=(3,)))  # first layer requires us to specify input_shape\n",
    "model.add(Dense(4)) # Second hidden layer\n",
    "model.add(Dense(3)) # Third hidden layer\n",
    "model.add(Dense(1)) # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829c731-4da2-47ec-b16f-1c8755b4842c",
   "metadata": {},
   "source": [
    "How do we know if our model was set up correctly? We can use the `summary()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae0947-a9fc-4e18-a384-cd62a5d91f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b69ef-a9cd-4acc-bcd0-ed941c75454a",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "Now that we have the model built, let's look at how we'd train these 39 parameters. We'll evaluate some ANNs with actual data later, but for now let's build a random dataset with 3 input parameters and one output parameter. \n",
    "\n",
    "We'll use pandas and numpy to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566ffc7-fe2d-4b26-a02c-f687fcc2f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "np.random.seed(123)\n",
    "X1 = np.random.normal(5,2,size=10000) # random variable with mean 5, SD 2\n",
    "X2 = (np.random.uniform(0,1,size=10000)>0.5).astype(int)\n",
    "X3 = np.random.exponential(2,size=10000)+2\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.stack([X1,X2,X3]).transpose(),\n",
    "                 columns = ['X1','X2','X3'])\n",
    "\n",
    "df['Y'] = 5*X1 - 2*X1**2 + X3/4 - 10*X2 + 10*np.log(X3)*X2 - X2/X3*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f386744-a77a-4511-ba7a-98d25d0f59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X1,df['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2c971-21c2-4def-8b9c-a5d519bb4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X2,df['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e45129-fd03-4bda-8c05-c1645625d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X3,df['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d336e61-1f16-40f3-8b3e-89efd4304445",
   "metadata": {},
   "source": [
    "Now that we have some data we can train the model. To do, we must `compile` the model and define the optimizer and loss function we wish to use. Let's define each of these:\n",
    "- **optimizer**: an algorithm or method used to adjust the parameters of a model during the training process in order to minimize the error or loss function. It determines how the model will update its internal parameters (weights and biases) based on the gradients computed during backpropagation. Examples include SGD, Adam (adaptive moment), Adagrad, etc.\n",
    "- **loss** (function): the key metric used during training to assess model quality; often determined by nature of outcome (e.g., continuous variables use something like MSE)\n",
    "\n",
    "We'll use \"adam\" for our optimizer and \"mse\" for our loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52146b7f-3958-43de-8144-a039f241a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6d264-8c77-4112-9700-ce5aec0da8f6",
   "metadata": {},
   "source": [
    "Next, we need to fit the model. Before doing so, though, let's train/test split our data so we can evaluate model fit out-of-sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea527d59-9621-4c04-a42c-78f16135a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,train_size=0.80,random_state=123)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434caf7-8d43-4bdb-89ab-b52772a396a7",
   "metadata": {},
   "source": [
    "Now we can fit the model, similar to how we've used the `fit()` method in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7633d9-064c-4230-b210-7a93d25afd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train[['X1','X2','X3']],train['Y'],epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef637e-03fa-4eaa-9a93-84c19a000501",
   "metadata": {},
   "source": [
    "Before moving on, we're going to introduce a few additional elements to this simple model:\n",
    "- activation functions: The power of ANNs comes from it's ability to learn non-linearities in data, and part of that power arises from the use of activation functions. Keras includes __[nine activation functions](https://keras.io/api/layers/activations/)__, plus the ability to build custom functions. We'll use \"relu\" for our nodes.\n",
    "- callbacks: During the fitting process, it's possible to employ \"callback functions\", which perform an inter-training step, like saving the model or evaluating the possibility of overfitting. We'll use __[EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)__ in this next training run.\n",
    "- validation_data: We know what this is, but we can actually incorporate it into our training procedure, which is very useful with the use of an early-stopping callback. \n",
    "\n",
    "Now we'll re-define the model with these new considerations and re-fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdaf97-e4d4-494e-8ee6-ef8d0819dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the model:\n",
    "model = Sequential()\n",
    "model.add(Dense(2,input_shape=(3,),activation='gelu'))\n",
    "model.add(Dense(4,activation='gelu'))\n",
    "model.add(Dense(3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "# Set up callback (early stopper) to monitor validation loss, and \n",
    "# have \"patience\" (how long to wait) of 5\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=5) \n",
    "\n",
    "# Fit\n",
    "model.fit(train[['X1','X2','X3']],train['Y'],\n",
    "          validation_data= (test[['X1','X2','X3']],test['Y']),\n",
    "          callbacks=[earlystopper],\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b710a-1d71-4da1-a20b-2920e2e5fdd5",
   "metadata": {},
   "source": [
    "Suppose we wanted to understand something about the average error in our dataset. We can generated predicted values to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a48a5-5960-40c6-bbf3-040d294145a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_Y'] = model.predict(df[['X1','X2','X3']])\n",
    "df['error'] = df['Y'] - df['predicted_Y']\n",
    "df[['Y','error']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce092bdf-0e93-4667-86d4-f4a6b94b9db6",
   "metadata": {},
   "source": [
    "## Using an ANN to detect Fake News \n",
    "### Data Setup\n",
    "Now that we've seen how to build a simple ANN with Keras, let's work on building an ANN to detect fake news!\n",
    "\n",
    "We're going to use a dataset from kaggle, available __[here](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)__. The data is comprised of a dataset of fake news (\"Fake.csv\") and real news stories (\"True.csv\"). Let's load each and set up a label to distinguish between the two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc135d-3f70-4f7f-b40d-3c22e5c70d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('/storage/ice-shared/mgt8833/classdata/Fake.csv')\n",
    "fake['label'] = 'Fake'\n",
    "real = pd.read_csv('/storage/ice-shared/mgt8833/classdata/True.csv')\n",
    "real['label'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9138622b-1356-433d-aa5e-f3a22ce30b70",
   "metadata": {},
   "source": [
    "These two datasets have the exact same columns, so we can simply stack them. I'm then going to do a random shuffle and reindex so it looks like what we'd expect a normal labeled dataset to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b28015-a149-4e9d-b1c4-e36e4a7fd149",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.concat([fake,real]).sample(frac=1,random_state=123).reset_index(drop=True)\n",
    "news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a736e1dc-4b59-4261-b78f-b36bfa0c86ef",
   "metadata": {},
   "source": [
    "We're going to use the \"text\" column of this dataset in a classifier. Before doing so, though, let's make one simple cleaning-related adjustment based on this quick observation of the data. Namely, \"real\" news often comes from Reuters, and we don't want that little bit of formatting to drive our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c98b13-4b36-48fb-93e1-07512c68b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.loc[news['label']=='True','text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562b438-bb99-41c0-a039-a02edd351ab9",
   "metadata": {},
   "source": [
    "We can use a simple regular expression to clear out this formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318bb15-4301-437a-a4d3-cb99e7c10046",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.loc[news['label']=='True','text'].str.replace(r'^[A-Z]+\\s+\\(Reuters\\)','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfad93-d49f-4f97-b5a3-9bf1feef027f",
   "metadata": {},
   "source": [
    "So we'll use that regular expression, adjusting to account for \"/\" and whitespace, to clean up the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816bf518-890b-4f49-b4da-c03b3b51abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['clean_text'] = news['text'].str.replace(r'^[A-Z/ ]+\\s+\\(Reuters\\)','',regex=True)\n",
    "news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3560e-730d-4f6e-b8e9-d3fa4a4ac511",
   "metadata": {},
   "source": [
    "Our labels are currently words, so let's set up an indicator variable. We could just use logic like we have before (e.g., `news['label']=='Fake'`, but instead lot's use `map()`, which would be easier to extend to multiple labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc558f09-b9ed-4e7c-9952-bd3f7a967f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['FAKE'] = news['label'].map({'Fake':1,'True':0})\n",
    "news['FAKE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f3711-8585-4559-a1f4-fe0e14629362",
   "metadata": {},
   "source": [
    "Now, let's create a document term matrix, which we'll then reduce using PCA. For our document term matrix we'll set the following parameters:\n",
    "- `max_features` = 1000\n",
    "- `stop_words` = \"english\"\n",
    "- `token_pattern` = \"\\b[a-zA-Z]{3,}\\b\"\n",
    "- `ngram_range` = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033638b-77e9-494d-bd81-5dd553fea7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2885fc-ef0d-4dee-907f-e48282199a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "vec = TfidfVectorizer(max_features = 1000,\n",
    "                      stop_words = 'english',\n",
    "                      token_pattern = r\"(?u)\\b[a-z]{3,}\\b\",\n",
    "                      lowercase = True,\n",
    "                      ngram_range = (1,2))\n",
    "dtm = vec.fit_transform(news['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a34ea-1952-4cec-ba66-84973028e554",
   "metadata": {},
   "source": [
    "Next, I want to normalize the data such that each record has unit length. We will use scikit-learn's normalize function (__[docs](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html)__). If you picture each numeric representation as a vector in 1,000-dimensional space, normalize will scale all vectors to have unit length (or length of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583c5ec-4e5e-4adb-9d35-a6218635e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "dtm_normed = normalize(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c0043-47de-41a7-9faf-30b6000cfc3b",
   "metadata": {},
   "source": [
    "Now would be a good time to consider an approach to reducing the dimensionality of the data. For instance, you could use:\n",
    "- Topic modeling (LDA, NMF)\n",
    "- PCA (probably \"Truncated SVD\" since the DTM is sparse)\n",
    "- UMAP (probably in conjunction with PCA)\n",
    "- Word embeddings (e.g., Word2Vec)\n",
    "\n",
    "It turns out the raw data in this instance, though, works pretty well. So for brevity we're going to move on to designing and training the ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa71a81-e005-4a56-84d8-bb7be7104eed",
   "metadata": {},
   "source": [
    "### Designing the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967eed6b-cc51-4b32-8cb6-17b3c681931b",
   "metadata": {},
   "source": [
    "Now we'll design an ANN to classify this dataset. Let's first split the data so we can use the holdout (validation) sample during model tuning. Note that Keras doesn't work with sparse matrices, so we need to move to a dense matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0112a5-ecbb-431b-9c70-264f4d6ee422",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX,trainY,testY = train_test_split(dtm_normed.todense(),news['FAKE'],train_size = 0.80,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a72f4-0a8a-41eb-aa5c-77a64655d979",
   "metadata": {},
   "source": [
    "Now we can set up the ANN. How do we choose the number of layers and nodes? There isn't a hard-and-fast rule for this. I decided to start with 2 hidden layers, each with 10 nodes. We'll also use relu activation on the hidden layers. \n",
    "\n",
    "Note that since this is a two-class, one-hot classification problem, we **must** use \"sigmoid\" activation on the output layer. This will produce a probability we can use to assign labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1edbf2d-ecc5-470d-bb31-04ce139ff5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(10,input_shape=(dtm_normed.shape[1],),activation='relu')) \n",
    "classifier.add(Dense(10,activation='relu')) # Second hidden layer\n",
    "classifier.add(Dense(1,activation='sigmoid'))# Output layer\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d18e7-a098-429f-93be-b0b366a53d64",
   "metadata": {},
   "source": [
    "This relatively simple model has over 10,000 parameters to train!\n",
    "\n",
    "We'll now compile and train the model. We'll use \"adam\" again for our optimizer, but we must use a different loss function since we're no longer dealing with a continuous output (MSE-type measures don't make sense). For this type of classification problem \"binary crossentropy\" is appropriate. We'll also include in the compiler an instruction to compute classification accuracy.\n",
    "\n",
    "To fit, we'll use the following parameters:\n",
    "- `epochs`: 50\n",
    "- `callbacks`: We'll use an early stopper again that monitors accuracy of the validation sample (\"val_accuracy\"). I'll set patience at 5.\n",
    "- `validation_data`: Pass the names of our \"test\" datasets, `testX` and `testY`\n",
    "- `use_multiprocessing`: `True` (speed things up)\n",
    "- `batch_size`: 32 (Note that this is the default, but you can change this. It's another hyperparamter to tune--certain data work best with smaller batch sizes, and others work best with larger).\n",
    "\n",
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf31fb1e-4f40-4c09-8484-5692a1cdde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "earlystopper = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "classifier.fit(trainX,trainY,epochs=50,callbacks=[earlystopper],\n",
    "               validation_data=(testX,testY), use_multiprocessing=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7eb8e-7abd-4330-86b9-f749c15eab8b",
   "metadata": {},
   "source": [
    "Wow! Very accurate, and very quickly! Should we be concerned?\n",
    "\n",
    "### Revisiting our data \n",
    "\n",
    "This truly is the first model I tried, but it did concern me so I checked a few things:\n",
    "1. Did we \"taint\" the model by including some function of the output as an input feature? **ANSWER**: No, I don't think so.\n",
    "2. Which features are important? **ANSWER**: None of them (commented code below)\n",
    "3. Are the input data for each class (fake and real) comparable? **ANSWER**: We normed all the vectors, so they should be comparable.\n",
    "4. What features are systematically different? **ANSWER**: See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09efd529-b768-4a10-957a-a8034eb2cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These next two cells compute feature importances using permutation importance, and the %%capture (magic) \n",
    "# limits the output of the first cell. While permuatation importance is a common way to get\n",
    "# a general sense of feature importance, it turns out no features (alone) affect accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79a556-2395-4696-b932-953fa85a2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # Uncomment this code if you want to run a feature importance analysis. I've commented so you can try to understand\n",
    "# # what's done\n",
    "# #THIS SAYS ALL FEATURES ARE WORTHLESS\n",
    "# def calculate_feature_importance(model, X, y, metric):\n",
    "#     baseline_score = metric(y, (model.predict(X)>0.5)[:,0].astype(int)) # computes current accuracy as baseline\n",
    "\n",
    "#     feature_importance = np.zeros(X.shape[1]) # generates vector of 0s of same shape as number of features\n",
    "#     for feature_index in range(X.shape[1]): # iterates over each feature\n",
    "#         X_permuted = X.copy() # copies the original X data into a new dataset\n",
    "#         np.random.shuffle(X_permuted[:, feature_index]) # randomly sorts one column of the data (feature_index)\n",
    "\n",
    "#         permuted_score = metric(y, (model.predict(testX)>0.5)[:,0].astype(int)) # uses the permutated data to re-compute accuracy\n",
    "#         feature_importance[feature_index] = baseline_score - permuted_score # computes feature importance as difference between baseline and permutated accuracy\n",
    "\n",
    "#     feature_importance /= baseline_score  # Normalize the importance values (scale by original accuracy)\n",
    "#     return feature_importance\n",
    "\n",
    "# # Calculate feature importance using permutation importance\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# feature_importance = calculate_feature_importance(classifier, testX, testY, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657e529-59f9-46d1-8b8e-6899eb0b837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print feature importance values\n",
    "# for feature_index, importance_value in enumerate(feature_importance):\n",
    "#     if importance_value > 0:\n",
    "#         print(f\"Feature {vec.get_feature_names_out()[feature_index]}: {importance_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1177c7a-f0ce-48de-b8fe-adea62f785ee",
   "metadata": {},
   "source": [
    "Let's see which features have the largest differences between real and fake news. To evaluate this, we need to:\n",
    "1. Separately compute the mean value for each feature by label\n",
    "2. Compute the difference between means\n",
    "3. Evaluate high and low differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c95c90-3a4b-4869-88cf-115babf272cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute value of each feature \n",
    "fake_means = np.asarray(dtm_normed[news['FAKE']==1,:].mean(axis=0)).flatten()\n",
    "real_means = np.asarray(dtm_normed[news['FAKE']==0,:].mean(axis=0)).flatten()\n",
    "means = pd.DataFrame(np.stack([fake_means,real_means]).transpose(),columns=['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374691d1-ccea-4e5b-bfe7-74231912348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the differences and set index equal to feature names:\n",
    "means['Difference'] = fake_means - real_means\n",
    "means.index = vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eaff1a-22e4-48f4-8c67-5fc20f18e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means.sort_values(by='Difference').head(25))\n",
    "print(means.sort_values(by='Difference').tail(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0312395-db65-4623-8375-4dbd901d345f",
   "metadata": {},
   "source": [
    "Overall, this provides me some comfort the model is actually using the data. The big things that jump out at me is that the \"real\" news tends to use very objective or \"checkable\" words (\"said\", days of week, offical titles, etc.). The fake news seems more casual, referring to social media, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb9b6b-c703-45ed-99da-77931efa5f91",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance & Applying to New Data\n",
    "The last two things we will do is look at how the model performs by class, similar to how we evaluated other classifiers. We'll also look at predictions for new data\n",
    "\n",
    "#### Evaluating Model Performance\n",
    "We've discussed that accuracy is not always the best means of evaluating a model. Let's take a deeper dive using some techniques we applied in earlier modules. Before doign so, though, we first need to generate predicted values. Let's look at the output of the `predict()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2f173-e103-4fc5-8a7a-23a258dcea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(dtm_normed.todense())\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ce1d1-c491-489d-b6fe-35b979fa03a6",
   "metadata": {},
   "source": [
    "A few things to observe here:\n",
    "- The output array is a function of the dimensions of the output layer. Our output layer had 1 node, so this is a 1 column array. If we had a three-state classification problem (e.g., negative, neutral, positive), this array would have 3 columns, one per output\n",
    "- If we had 3 or more classes, we would likely use `argmax()` to determine which class had the highest probability (assuming a `softmax` classification problem)\n",
    "- In our case, we'll use probabilities above 50% for 1s (Fake), and otherwise 0 (Real). This conversion is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7314b68-3f53-46f8-bb51-4ab735068b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['pred_fake'] = (predicted>0.50).flatten().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945a973-5509-49b0-9bba-9b7b4be6b9d9",
   "metadata": {},
   "source": [
    "Now we can use any of our sklearn classification metrics to evaluate. Let's look at the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2851e-dd11-4cf3-9675-edfb8df624e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(news['FAKE'],news['pred_fake']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2398180-8c28-49a4-80b5-4caf63a2be69",
   "metadata": {},
   "source": [
    "What about the 1%? If we want to look at any of those, we can simply examine rows where predicted doesn't equal actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dbca1-5a27-4ab4-bc66-d65811ecd59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass = news.loc[news.eval(\"FAKE != pred_fake\")]\n",
    "misclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4991ea-bb33-412c-bb7c-0772b9b9a75a",
   "metadata": {},
   "source": [
    "Last, let's see how this classifier works for news outside the source used to train. Specifically, I provide a file, \"gpt_news.csv\", which includes 5 \"fake news\" articles and 5 \"real news\" articles generated by ChatGPT. \n",
    "\n",
    "Let's first load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bbf22-121f-4911-b1d4-2f489c4d1fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt = pd.read_csv(\"/storage/ice-shared/mgt8833/classdata/gpt_news.csv\")\n",
    "gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb22ea9-be54-45fc-a758-50a952527d8e",
   "metadata": {},
   "source": [
    "You're welcome to look at any of these articles in more detail, but the fake news articles include topics like aliens, time travel, and vampires. The real articles discuss covid, a Mars rover, and climate change. So, topically they are very different. \n",
    "\n",
    "Let's see how the classifier performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d674b-bd0b-4188-a2b1-0dad75bf9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake articles\n",
    "classifier.predict(normalize(vec.transform(gpt['gpt_fake'])).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03527541-828c-4060-b1f9-01b723db36e8",
   "metadata": {},
   "source": [
    "Four of 5 on the fake side. Now the real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d2142-01e5-439a-9e10-edb82b139304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real articles\n",
    "classifier.predict(normalize(vec.transform(gpt['gpt_real'])).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a15ab-c579-49f6-bf62-ca26bb23ba9c",
   "metadata": {},
   "source": [
    "Much worse! Only two of 5 correctly identified.\n",
    "\n",
    "This illustrates the importance of how specific corpuses of data can produce models that perform well in one setting, but more poorly in others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac9d8a-dada-4aae-83db-182a0147e94c",
   "metadata": {},
   "source": [
    "### Wrap Up \n",
    "This demo gave you a (brief) introduction into Keras and Tensorflow. ANNs are extremely powerful tools for classification and prediction in general, and particularly in processing unstructured data (NLP, image classifiers, etc.). We used Keras for an NLP classification task, but you could also use Keras for:\n",
    "- regression problems\n",
    "- multilabel classification (e.g., topic identification)\n",
    "- multiclass (>3) classification (e.g., cluster prediction)\n",
    "Note that each of these requires some tweaks, such as different output layer activation and loss functions.\n",
    "\n",
    "One thing we did not discuss was tuning hyperparamters in an ANN. Keras includes some functionality that makes it possible to tune Keras models in a manner very similar to how we tuned scikit-learn classifiers. See __[here](https://medium.com/swlh/hyper-parameter-tuning-for-keras-models-with-scikit-learn-library-dba47cf41551)__ for an example of tuning an image classifier. \n",
    "\n",
    "Keras can also be used to build more advanced ANNs, such as those including LSTM layers, recurrent ANNs, and convolutional ANNs. There are many resources available online that illustrate those topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:week7a]",
   "language": "python",
   "name": "conda-env-week7a-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
